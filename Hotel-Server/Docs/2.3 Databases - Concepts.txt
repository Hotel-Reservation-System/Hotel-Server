1. DATABASE: CONCEPTS

This file will discuss database concepts that you need to set up and work with databases.
The next document, '2.4 Databases - Practical Applications', will discuss the 
installation and configuration of a database, followed by a section on how to connect a 
program to a database.

In this file, Section 2 will explain what databases are, and list some key things that 
you need to know about them. Section 3 is concerned with program-database interfacing: 
How does a program talk to a database? What role does an ORM library play in facilitating
this communication? 


    2.    Introduction to Database Concepts and Terms
    2.1   What is a Database?
    2.2   Relational Database Management Systems (RDBMS)
    2.3   Other Database Concepts and Terms to Learn Before Proceeding to Section 3
    
    3.    Application-Database Communication Concepts
    3.1   Entity Framework Core
    3.2   How Does Entity Framework Core Translate Data To and From the Database?
    3.2.1 Database Providers
    3.2.2 The Program-side Representation of Database Entities: The Data Model vs. The Schema
    3.2.3 Migrations
    

****************************************************************************************************
****************************************************************************************************


2. INTRODUCTION TO DATABASE CONCEPTS AND TERMS

2.1 WHAT IS A DATABASE?

A database is an software system that stores data. A snippet I found on the internet 
describes databases like this: "A database is a computerised system that makes it easy to 
search, select and store information." Databases are used in institutions and businesses 
to store organizational data like customer records and profiles, sales transactions, 
product information etc. Computers, web browsers and phones have many built-in databases
for tracking information. However, storing data is not worthwhile unless the database is 
secure and well-organized, yet easily accessible to those who have authorization.

This is why a database program is rarely marketed as a standalone piece of software; 
instead most databases come with an ecosystem of additional tools. This collection of 
database and tooling is called a Database Management System (DBMS). A DBMS comes with 
tools to facilitate things like security rules and user access management, user 
authentication, search optimization, data management (Data integrity, encryption, 
compression, de-duplication, backup and recovery etc.), report generation etc. 

In 'Databases: A Beginner's Guide', Andy Oppel provides some definitions for terms 
related to databases[1]:
 
 
    1. Database Object (Page 4): "A database object is a named data structure that is 
       stored in a database. The specific types of database objects supported in a 
       database vary from vendor to vendor and from one database model to another."
       
    2. Database Model (Page 4): "Database model refers to the way in which a database 
       organizes its data to pattern the real world." 
       
       Historical database models include Flat File, Hierarchical, Network and the 
       Inverted file model. Some modern niche database models: Object-oriented, 
       Object-Relational, Graph, Document-oriented, and NewSQL.
    
       The most common modern database models are Relational and NoSQL.
    
    3. File (Page 4): A file is a collection of related records that are stored as a 
       single unit by an operating system. Given the unfortunately similar definitions of 
       files and databases, how can we make a distinction?… The answer lies in an 
       understanding of certain characteristics or properties that databases possess 
       which are not found in ordinary files, including the following:
    
           * Management by a database management system (DBMS)
           * Layers of data abstraction
           * Physical data independence
           * Logical data independence
    
    4. Database Management System (DBMS) (Page 5): The database management system (DBMS) 
       is software provided by the database vendor. Software products such as Microsoft 
       Access, Oracle, Microsoft SQL Server, Sybase ASE,DB2, Ingres, and MySQL are all 
       DBMSs…
    
       The DBMS provides all the basic services required to organize and maintain the 
       database, including the following:
    
       * Moves data to and from the physical data files as needed.
       * Manages concurrent data access by multiple users, including provisions to prevent 
         simultaneous updates from conflicting with one another.
       * Manages transactions so that each transaction’s database changes are an 
         all-or-nothing unit of work. In other words, if the transaction succeeds, all 
         database changes made by it are recorded in the database; if the transaction 
         fails, none of the changes it made are recorded in the database.
       * Supports a query language, which is a system of commands that a database user 
         employs to retrieve data from the database.
       * Provides provisions for backing up the database and recovering from failures.
       * Provides security mechanisms to prevent unauthorized data access and modification.


2.2 RELATIONAL DATABASE MANAGEMENT SYSTEMS (RDBMS)

Andy Oppel explains the Relational Model on pages 17-19[1]:


    In addition to complexity, the network and hierarchical database models share another 
    common problem—they are inflexible. You must follow the preconceived paths through 
    the data to process the data efficiently. Ad hoc queries, such as finding all the 
    orders shipped in a particular month, require scanning the entire database to locate 
    them all. Computer scientists were still looking for a better way…
    
    The relational model is based on the notion that any preconceived path through a 
    data structure is too restrictive a solution, especially in light of ever-increasing 
    demands to support ad hoc requests for information. Database users simply cannot 
    think of every possible use of the data before the database is created; therefore, 
    imposing predefined paths through the data merely creates a “data jail.” The 
    relational model allows users to relate records as needed rather than as predefined 
    when the records are first stored in the database. Moreover, the relational model 
    is constructed such that queries work with sets of data (for example, all the 
    customers who have an outstanding balance) rather than one record at a time, as 
    with the network and hierarchical models.
    
    The relational model presents data in familiar two-dimensional tables, much like 
    a spreadsheet does. Unlike a spreadsheet, the data is not necessarily stored in 
    tabular form and the model also permits combining (joining in relational terminology) 
    tables to form views, which are also presented as two-dimensional tables. In short, 
    it follows the ANSI/SPARC model and therefore provides healthy doses of physical and 
    logical data independence. Instead of linking related records together with physical 
    address pointers, as is done in the hierarchical and network models, a common data 
    item is stored in each table, just as was done in flat file systems…
    
    The elegant simplicity of the relational model and the ease with which people can 
    learn and understand it has been the main factor in its universal acceptance. The 
    relational model is the main focus of this book because it is ubiquitous in today’s 
    information technology systems and will likely remain so for many years to come.


In the Relational Model, two pieces of data are linked to each other with respect to the 
relationship they have to another. A table is a physical representation of a relation.

This article will only consider the most common kind of databases, the Relational 
Database Management System. Here is an explanation of RDBMSes[2]: 


    1. Relational Databases: Relational database management systems (RDBMS) support the 
       relational (=table-oriented) data model. The schema of a table (=relation schema) 
       is defined by the table name and a fixed number of attributes with fixed data 
       types. A record (=entity) corresponds to a row in the table and consists of the 
       values of each attribute. A relation thus consists of a set of uniform records.
    
       The table schemas are generated by normalization in the process of data modeling.
    
       Certain basic operations are defined on the relations:
    
       * classical set operations (union, intersection and difference)
       * Selection (selection of a subset of records according to certain filter criteria 
         for the attribute values)
       * Projection (selecting a subset of attributes / columns of the table)
       * Join: special conjunction of multiple tables as a combination of the Cartesian 
         product with selection and projection.
         
      These basic operations, as well as operations for creation, modification and 
      deletion of table schemas, operations for controlling transactions and user 
      management are performed by means of database languages​​, with SQL being a well 
      established standard for such languages.
    
      The first relational database management systems appeared on the market at the 
      beginning of the 1980s and since have been the most commonly used DBMS type.
    
      Over the years, many RDBMS have been expanded with non-relational concepts such as 
      user-defined data types, not atomic attributes, inheritance and hierarchies, which 
      is why they are sometimes referred to as object-relational DBMS.
      
      
Here is a list of well known RDBMSes:


    Oracle
    MySQL
    Microsoft SQL Server
    PostgreSQL
    DB2
    Microsoft Access
    SQLite
    Teradata
    MariaDB


The most popular open source databases as of October 2018 are: PostgreSQL and SQLite. 
Both are robust and capable. 

SQLite is designed to be a light-weight, server-less single file database. It's used in 
electronic devices like phones, PDAs, MP3 players as well as web browsers. If you need a
low footprint, high-quality database, go with SQLite.

PostgreSQL is a open source, fully featured RDBMS. It's more powerful than MySQL/MariDB,
but it has better data integrity. It will serve well as the database for web applications
and for other kinds of heavier duty software.   
 
 
2.3 OTHER DATABASE CONCEPTS AND TERMS TO LEARN BEFORE PROCEEDING TO SECTION 3

There is much more to learn about databases before proceeding to Section 3. Here are 
lists of such things, mostly taken from Caleb Curry's website.[3]


SQL

You should know the basics of SQL, because this is the language of databases.
 

DATA

    * Data
    * Database
    * Relational Database
    * Database Management System
    * Relational Database Management System
    * Null
    * Anomalies
    * Referential Integrity 


DATABASE COMPONENTS

    * Entity
    * Attribute
    * Relation
    * Tuple
    * Table
    * Row
    * Column
    * File
    * Record
    * Field
    * Value
    * Entry
    * Database Design
    * Schema
    * Normalize
    * Naming Conventions
    * Keys
    

CONCEPTUAL DATABASE DESIGN CONCEPTS

Andy Oppel explains on page 30: [1]

    … involves studying and modeling the data in a technology-independent manner. The 
    conceptual data model that results can be theoretically implemented on any database 
    or even on a flat file system. The person who performs conceptual database design 
    is often called a data modeler.


    * Entity vs. Entity-Type
    * External Entities
    * Attributes
    * Relationships
    * One-to-One Relationships
    * One-to-Many Relationships
    * Many-to-Many Relationship
    * Recursive Relationships 
    * Business Rules
    
    
LOGICAL & PHYSICAL DESIGN CONCEPTS

Andy Oppel explains on page 30: [1]

Logical Database Design


    …is the process of translating, or mapping, the conceptual design into a logical 
    design that fits the chosen database model (relational, object-oriented, 
    object-relational, and so on). A specialist who performs logical database design is 
    called a database designer, but often the database administrator (DBA) performs all 
    or part of this design step.


Physical Database Design

    The final design step is physical database design, which involves mapping the logical 
    design to one or more physical designs, each tailored to the particular DBMS that 
    will manage the database and the particular computer system on which the database 
    will run. The person who performs physical database design is usually the DBA.


    * Tables
    * Columns and Data Types
    * Constraints
    * Primary Key Constraints
    * Primary Key Constraints
    * Intersection Tables
    * Intersection Tables
    * NOT NULL Constraints
    * CHECK Constraints
    * Constraint Enforcement Using Triggers
    * View


ENTITY-RELATIONSHIP MODEL

In the context of a database, an entity–relationship model (ER model for short) 
describes relationships between instances of entities.


    * Keys (Primary, Foreign, Compound, Alternate etc.)
 
 
****************************************************************************************************
****************************************************************************************************
   

3. APPLICATION DATABASE COMMUNICATION CONCEPTS

3.1 ENTITY FRAMEWORK CORE

When you start up a program that uses a database, as this one does, one of the first 
things the program will do is try and talk to the database. A database usually 
understands only the the SQL language. When you connect a database to a program written 
in C# or another general purpose programming language, you need an translator program to 
translate SQL to C# and vice versa. A program that translates SQL to a general purpose 
programming language like Java, C# or JavaScript and vice versa is called an 
OBJECT-RELATIONAL MAPPER (ORM).


                                          +---------+
                                          |         |
                                          | PROGRAM |
                                          |         |
                                          +----+----+
                                               ^
                                               |
                                               v
                                         +-----+-----+
                                         |           |
                                         | ENTITY    |
                                         | FRAMEWORK |
                                         | CORE      |
                                         |           |
                                         +-----+-----+
                                               ^
                                               |
                                               v
                                         +------------+
                                         |            |
                                         |  DATABASE  |
                                         |            |
                                         +------------+


Entity Framework Core (from here on in referred to as EFC or EF Core) is an ORM that sits 
between a app server like Hotel-Server and its database. When you hook it up to a data 
source, such as a database, an ORM reads in raw SQL data and turns it into collections of 
C# objects for use in the program. By doing this, EF Core is translating data as it is 
represented in the database into a data representation that C# programs would understand.

Entity Framework Core is the standard ORM solution in the .NET world, provided by 
Microsoft for .NET Core projects. You'll need several nuget packages to get EF Core 
functionality: 


    Microsoft.EntityFrameworkCore, 
    Microsoft.EntityFrameworkCore.Relational, and 
    Microsoft.EntityFrameworkCore.Tools (For Migrations. Tools for Package Manager Console.)
    
    
Fortunately, all these packages come with the Microsoft.AspNetCore.All metapackage, which 
appears to be mandatory for all ASP.NET Core projects. If you want to use the command 
line interface while working with migrations, you will have to install this package, 
which must done separately:


    Microsoft.EntityFrameworkCore.Tools.DotNet (For Migrations. Tools for the Command-line 
                                                Interface. )
                                                

Note: The docs say that "You have to install this package by editing the .csproj file; 
you can't use the install-package command or the package manager GUI."



3.2 HOW DOES ENTITY FRAMEWORK CORE TRANSLATE INFORMATION TO AND FROM THE DATABASE?

Consider this table from a database, called Contacts:

+----+-----------+----------+----------------+
| Id | FirstName | LastName |  PhoneNumber   |
+----+-----------+----------+----------------+
|  1 | Bonnie    | Tsing    | (123) 456-7890 |
|  2 | Barry     | Forg     | (198) 928-9834 |
|  3 | Linda     | Blom     | (234) 239-9231 |
+----+-----------+----------+----------------+

The table contains 3 records. Each record has 4 fields. Each record contains Contact 
information for one person. This is how data is stored and represented in a database. 

There are other ways to represent this data. Take a look at the C# model class below: 


    public class Contact
    {
        [Required]
        public int Id { get; set; }
        
        [MinLength(2)] 
        [MaxLength(50)]
        public string FirstName { get; set; }
        
        [MinLength(2), MaxLength(50)]
        public string LastName { get; set; }

        [Phone]
        public string PhoneNumber { get; set; }
    }
    
    
The Contact class has a name similar to the table and it has four properties, but what is 
most interesting is that the property names - Id, FirstName, LastName and PhoneNumber - 
are the same as the column names in the Contacts table above. Do you see where this is 
going?

Put simply, records in a database can be converted into C# objects. The structure of a 
table in a database, such as the Contacts table above, can be represented in a C# program 
in the form of a C# POCO (Plain Old Class Object) model class. Columns in a table can be 
mapped to properties in the class. The information in a record from the Contacts table 
can be represented in the form of a Contact object. To say it again, data contained in a 
record from a database table can transmuted into a form recognizable and usable in a C# 
program - a C# object.  

This is Entity Framework Core's job: to map records from tables in a database to a 
collection of C# objects and and the reverse. More specifically, EF Core acts as a 
translation layer between the Hotel Reservation System project and its database, 
translating C# code into SQL commands and C# objects into records in the database and 
vice versa, all without writing any SQL.

EF Core needs several things to set up the program to interface with a database. These 
are the concepts you need to understand:


     1) Database Provider,          (Defined in Data/MyDbContextFactory.cs)
     2) Data Model,                 (Defined in the Models folder of the Common project)
     3) Database Schema,            (Defined in Data/Context.cs)
     4) Migrations                  (Generated into the Data/Migrations Folder)


The next three sections explain these concepts.


3.2.1 DATABASE PROVIDERS
 
A Database Provider is a "a software library consisting of classes that provide data 
access services such as connecting to a data source, executing commands at a data source 
and fetching data from a data source with support to execute commands within 
transactions. It resides as a lightweight layer between data source and code, providing 
data access services with increased performance."[4] 

A DATABASE PROVIDER is a small library that helps EF Core to speak to databases from a 
certain vendor. For instance, there are Database Providers for SQL Server, SQLite, 
PostgreSQL and other databases. EF Core can talk to any database if it has the database 
provider library for it. When Hotel-Server is run, Entity Framework will be brought 
online to talk to the database. The first thing EFC will do is search for the Database 
Provider. 

Therefore, you need to find the right database provider for the database in your project 
and add it to the program via a Nuget package. The Database Provider for this project is 
the 'Npgsql.EntityFrameworkCore.PostgreSQL' package. By using this package, EF Core will 
come to know that this project uses a PostgreSQL database. Through it, EFC can interface 
with the database and carry out operations on it. 

Once it can talk to the database, EF Core will will use the Data Model to transform a 
SQL query into an object model representation of a query (which is called a canonical 
command tree) and vice versa. .NET Database Providers can consume canonical command trees 
to talk the database.

The Data Provider, connection string and other related features can be configured in: 


    * Data/MyDbContextFactory.cs, OR
    * ConfigureServices() method of Startup.cs 
    

To learn more about database providers, go to: https://docs.microsoft.com/en-us/ef/core/providers/


3.2.2 THE PROGRAM-SIDE REPRESENTATION OF DATABASE ENTITIES: THE DATA MODEL vs. THE SCHEMA

Once EF Core confirms that it can talk to the database via the database provider, it 
will need the Data Model and Schema of the database. What are those things and why does 
your database need them? Recall that it is EFC's job to do two-way translations between 
your program and the database. This involves mapping tables and other databases entities 
to C# objects and vice versa. To do this, EF Core must have a program-side representation 
of entities your program will want to store in the database. This includes entity and 
attribute names, and their relationships expressed in C# code. The Data Model and the
Schema are precisely that: representations of database entities and their relationships. 

A short discussion is in order on when and how the data model and schema is to be 
written. When the programmer first starts writing an ASP.NET Core program, she typically
starts by defining the entities in that project. These entities are usually defined as
POCO classes in the 'Models' folder of your solution. In the eyes of EFC, these model 
classes are the Data Model. When preparing a greenfield database for your program, you 
have to write the schema for it. To write the schema, the programmer will have to 
consult the Data Model.

Let's move on to studying these two things. The Data Model is distinct from a Database 
Schema; see this StackOverflow Answer from richik jaiswal to learn the difference[5]:


     A schema is a blueprint of the database which specifies what fields will be present 
     and what their types will be. For example an employee table will have an employee_ID 
     column represented by a string of 10 digits and an employee_Name column with a 
     string of 45 characters.
     
     Data model is a high level design implementation which decides what can be present 
     in the schema. It provides a database user with a conceptual framework in which we 
     specify the database requirements of the database user and the structure of the 
     database to fulfill these requirements.
     
     A data model can, for example, be a relational model where the data will be 
     organised in tables whereas the schema for this model would be the set of attributes 
     and their corresponding domains.


A Data Model is an abstract formalization of a database's entities. The basic properties 
of database entities like tables and columns are defined as C# model classes. The model 
classes in the 'Models' or 'Entities' folder of your project form the DATA MODEL for your 
database. 

For an example, let's take another look at the Contact class from section 3.2:


    public class Contact
    {
        [Required]
        public int Id { get; set; }
        
        [MinLength(2)] 
        [MaxLength(50)]
        public string FirstName { get; set; }
        
        [MinLength(2), MaxLength(50)]
        public string LastName { get; set; }

        [Phone]
        public string PhoneNumber { get; set; }
    }


The Contact class is a data model class: it's serves as very abstract, high-level C# 
representation of the Contacts table in your database. When EFC tries to talk to the 
Contacts table in your database it will first consult its C# counterpart, the Contacts 
data model class, to learn the topology of this entity. 

Note that the properties of this class have data annotation attributes on them. These 
annotations mandate values for the 'Id' property and establish value minimums and 
maximums on the 'FirstName' and 'LastName' properties. As the data model informs the 
schema, when the schema is written, these restrictions will carry over to it. In fact,
when the programmer first writes the schema for a new database, she usually derives it 
from the data model. 

Go to this location to see the model classes for this project.


    /Common/Models/Tables


Let's move on to discussing the schema. The DATABASE SCHEMA is a more specific definition 
of a database's entities and their attributes. It serves as a snapshot of the database's 
topology at the current point in time. The schema takes entities defined in the data 
model, plus any data annotation attributes defined therein, and adds other things to it. 
This may include restrictions on character length for a field, marking certain fields as 
mandatory when a record is created, and establishing the nature of relationships between 
entities. 

For new databases, the schema has to be written by the programmer. However, if a database 
already exists, you can join it to an ASP.NET Core project and then generate a schema 
from it. 

Let's take a look at what a schema looks like. First, here's the Hotel model class (from 
the Models folder): 


    public class Hotel : IObjectWithState
    {
        // ORMs (Object-Relational Mapper) map properties in an object to a table. The 
        // ObjectState property is not a table column; it is used to track changes in an 
        // entity. This will likely happen in the endpoints of this project.
        [NotMapped]
        public ObjectState State { get; set; }
        
        
        // The primary key of the Hotel table in the Database is the Room Number.
        [Key]
        public long Id { get; set; } 
        public string Name { get; set; }
        public string Address { get; set; }
        public string PhoneNumber { get; set; }

        // Hotel Objects have a HotelRooms property to track the list of hotelrooms at a
        // hotel without needing to query the database.
        public virtual IEnumerable<HotelRoom> HotelRooms { get; set; }
    }
    

There are schemas for at least three levels of a database: physical schema (how data 
blocks are stored at the lowest level; this is where database designers work), logical 
schema (how records get stored in data structures; this level is where programmers and DB 
administrators work) and view schemas (which are schemas for end-user interaction). 

Taken from Context.cs, here is the corresponding Schema for a Hotel table:


    public class Context : DbContext
    {
        public virtual DbSet<Hotel> Hotels { get; set; }

        protected override void OnModelCreating(ModelBuilder modelBuilder)
        {
            modelBuilder.Entity<Hotel>(entity =>
            {
                entity.HasKey(e => e.Id);
                entity.Property(e => e.Id).IsRequired().ValueGeneratedOnAdd();
                entity.Property(e => e.Name).IsRequired().HasMaxLength(100);
                entity.Property(e => e.Address).IsRequired().HasMaxLength(200);
                entity.Property(e => e.PhoneNumber).IsRequired().HasMaxLength(100);
            });
        }
    }
        

When any ASP.NET Core program runs normally, EF Core will be sitting between the program 
and its database, translating SQL and database records into C# commands and objects. 
Provided it has the data model and the schema, EF Core has a map to the layout of any 
particular database.

Let's talk about the schema for the Hotel table; EF Core is going to use it to 
translate entities from the database into C# objects. When EF Core converts information 
from a data source into C# objects it needs two things: a pre-defined C# model class that 
can represent data from each table and a collection to hold these model objects. 

Let's talk about the Hotels DbSet<Hotel> data structure first. DbSet<Hotel> is a generic 
data structure that can contain only Hotel objects. This is the first thing that is 
declared in the schema: a data structure to hold Hotel objects as they get converted from 
records, called Hotels.

The purpose of a Schema is to define the specific shape and form of the entities in a 
table. Following the declaration of Hotels DbSet, comes the OnModelCreating() method. 
This method is overridden and the schema is defined within; it lays out primary keys for 
tables and Navigation properties (foreign keys) between entities. Lastly, we can also 
define field constraints in this method, which are specifications and limitations for 
every column in the Hotel Table. For instance, HasKey() denotes the Id field as the 
Primary Key of a table. The other properties are defined with the Property() method. The 
Id, Name, Address and PhoneNumber fields are marked as required fields. The character 
lengths of each field are also specified. 

As EF Core converts every record into a new object in a DbSet<T> collection or vice 
versa, it makes sure that all these requirements are met. The fields of each record in 
the table are copied and assigned to the properties of a new C# object. Once a new Hotel 
object is populated with data from a record, it gets stored in the Hotels collection.

In case it was not clear, the schema for an ASP.NET Core solution can usually be found 
in:


/Data/Context.cs


3.2.3 MIGRATIONS

WHAT ARE MIGRATION? WHY DO WE NEED THEM?

During the course of developing a software solution, your program and its database will
grow and change. This section will focus on managing change in databases.

Recall that the Schema is a more specific map to the database than the Data Model. The 
schema of a database defines tables, specifies columns and their types, and the 
relationships between tables, i.e. it concretely describes the structure and topology of
the database. It also imposes constraints on data that seeks to enter the database.

However, a database is not a static thing; it changes with its program. In other words, 
during the lifetime of a database, its topology is in constant flux. In order to make any 
changes to fundamental entities in a database or their relationships, the programmer 
will have to modify the schema. Tables and attributes can be modified, added or deleted
by making changes to the schema. Corresponding changes will also have to be made to the
Data model classes.  

Changes to a database are complicated by the fact that organizations usually have 
multiple instances of a database. For instance, a company may have a development 
environment where software is developed, a production environment where stable software 
runs and perhaps a demo environment for demonstrating products to clients. If the 
development team makes changes to the master database, how are they going to roll out 
changes to all instances of the database? Databases change often enough that their Schema 
needs version control. 

A schema defines the topology of a database at one point in time. Usually, the schema 
only contains the current topology of the database. However, it would be very useful to 
have snapshots of the schema every time it was changed. This is where SCHEMA MIGRATIONS 
(often called MIGRATIONS) come in. Schema snapshots are called MIGRATIONS and they serve 
as version control for a database's schema. 

To track changes to the schema, you can generate a migrations file. Migration files 
contain only delta values, i.e. only changes from the previous migration file. Your 
program usually has one active schema file, but many migrations files. You can use 
migrations to update to or rollback from a version of the database's schema. A migration 
file will  have a way to revert its own changes. It may also contain scripts to enact 
transformations and to insert default data into the database by populating tables and 
columns.

To ensure data integrity, it is a best practice to take a snapshot of a database's 
topology every time a change is made to the schema. When you first write the schema for a 
new database, you should generate a migration file that contains the entire schema. 
Subsequently, every time you change entities or their relationships by editing the 
schema, you will want to generate a new migration file that contains the new, updated 
topology of the database. Once again, do note that the new migration file only contains 
delta values, i.e. only changes from the previous migration file.

Migrations are constantly generated in the development stage of an application, because 
that's when the schema is changing the most. Large architectural changes and feature 
churn necessitate frequent alterations to the database's schema. Migrations are also 
needed when upgrading a database, switching to another database vendor, or moving a 
database into the cloud. Having a version controlled history of the database's schema 
(which captures the changes made to the database over time) gives you the ability to 
migrate the database to older or newer versions of the schema. Migrations are a 
convenient way to track your database's schema over time in a predictable and 
consistent way. By using migrations, you can update all instances of a database 
automatically and reliably to the schema version of your choice.
 
Typical location of migration files: Data/Migrations/ 


THE CONTENTS OF A MIGRATIONS FILE

Every migration file will contain an Up() and Down() method. The Up() method contains 
transformations to the schema of the Database. The Down() method just rolls back 
transformations in the Up() method i.e. it returns the schema to the state in the Up() 
method of the previous migration. The database schema should be unchanged if a call to 
Up() is followed by a Down(). If another, new migration file has been generated and 
needs to be applied to the database, call its Up() method. To revert these 
transformations, call its Down() method. 

The final set of transformations in a long chain of such changes is described in the 
Up() method of the last migration. The current state of a database's schema is the 
result of calling the Up() methods of all previous Migrations. 

Here is a answer from StackOverflow that expands on migrations[6]:

    DB Migrations make changes to your database to reflect the changes made to the Entity 
    Framework Model. These changes are added to the database with the Up method.
    
    When you want to rollback a change (e.g. by rolling back a changeset in TFS or Git), 
    the changes in the database have to be rolled back also because otherwise your Entity 
    Framework model is out-of-sync with the database. This is what the Down method is 
    for. It undo's all changes to the database that were done when the Up method was run 
    against the database.
    
    The Seed method gives you the ability to Insert, Update or Delete data which is 
    sometimes needed when you change the model of the database. So the Seed method is 
    optional and only necessary when you need to modify existing data or add new data to 
    make the model working.
    
    - Ric .Net    
    
Leaving aside the Seed method, which appears to from another framework, let's take a look 
at a migrations file. Taken from the file called, 
'20180128032156_CreateHotelHotelRoomRoomTypeBedTypeRoomReservationTables.cs', this is the 
Logical schema for the Hotel table: 


    public partial class CreateHotelHotelRoomRoomTypeBedTypeRoomReservationTables : Migration
    {
        protected override void Up(MigrationBuilder migrationBuilder)
        {
            migrationBuilder.CreateTable(
                name: "Hotels",
                columns: table => new
                {
                    Id = table.Column<long>(type: "int8", nullable: false)
                        .Annotation("Npgsql:ValueGenerationStrategy",
                                     NpgsqlValueGenerationStrategy.SerialColumn),
                    Address = table.Column<string>(type: "varchar(200)",
                                                   maxLength: 200,
                                                   nullable: false),
                    Name = table.Column<string>(type: "varchar(100)",
                                                maxLength: 100,
                                                nullable: false),
                    PhoneNumber = table.Column<string>(type: "varchar(100)",
                                                       maxLength: 100,
                                                       nullable: false)
                },
                constraints: table =>
                {
                    table.PrimaryKey("PK_Hotels", x => x.Id);
                });
        }
    }
    

GENERATING, APPLYING AND REMOVING MIGRATIONS
    
Migrations are generated or applied with CLI commands. 

Migrations files for .NET Core projects can be generated either through .NET Core CLI or 
terminals built into IDEs. Note that Jetbrains Rider cannot and does not support Visual 
Studio's Package Manager Console commands. Check if this changes in the future.

What happens when a migration is generated? When the command is given, it appears that 
Entity Framework Core combines the existing Schema with type information and data 
annotations from Model classes to generate a migration file. Generating a Migration will 
create a new file in the Migrations folder. It will contain a a user-named class that is 
a subclass of Entity Framework Core's Migration class. You may need to manually remove 
things from either method if it added more than the changes you made to the Schema. Make 
sure you read the migration file before applying it.

Here are two basic commands for generating and using migrations. Check the Entity 
Framework Core docs for more.

    1. GENERATING MIGRATIONS: Creates a new migration. The migration name should describe 
       in pascal case, the changes you made to the data model. 
    
       Visual Studio: add-migration <MigrationName> 
       E.g.: add-migration AddUserUserPreferenceUserInformationRoleUserRoleTables
    
    
    2. UPDATING DATABASE TO THE LATEST MIGRATION: Runs the Up() method of all migrations. 
    
       Visual Studio: update-database


    
MIGRATIONS: THE WORKFLOW 

This is the workflow for changing the schema and generating migrations:


In the Development Environment:

    1. When you need to add tables or modify relations in the database, edit the Schema 
       in Context.cs.
    2. Because the Schema has been modified, you need to generate a new migrations file.
    3. You run the migration file in the development environment to verify that it works 
       as intended. 


In the Production, Demo and other Environments:
    
    4. Deploy and run the migrations file in other environments to update these instances 
       of the database to the latest version of the schema.
    5. Verify that migration has gone smoothly in these environments as well.
    

****************************************************************************************************
****************************************************************************************************


SOURCES

01: Databases - A Beginner's Guide (Andy Oppel, 2009)
02: https://db-engines.com/en/article/RDBMS
03: https://www.calebcurry.com/beginner-database-terms/
04: https://www.techopedia.com/definition/25227/net-data-provider
05: https://stackoverflow.com/questions/25093452/difference-between-data-model-and-database-schema-in-dbms
06: https://stackoverflow.com/questions/36650268/the-difference-between-the-up-and-down-methods-in-the-migration-file
